{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import linear_models.softmaxreg as softmaxreg\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import metrics.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 0 acc 0.4\n",
      "it 10 acc 0.48333333333333334\n",
      "it 20 acc 0.7916666666666666\n",
      "it 30 acc 0.8333333333333334\n",
      "it 40 acc 0.8333333333333334\n",
      "it 50 acc 0.8333333333333334\n",
      "it 60 acc 0.8166666666666667\n",
      "it 70 acc 0.825\n",
      "it 80 acc 0.8416666666666667\n",
      "it 90 acc 0.85\n",
      "it 100 acc 0.85\n",
      "it 110 acc 0.8583333333333333\n",
      "it 120 acc 0.85\n",
      "it 130 acc 0.8416666666666667\n",
      "it 140 acc 0.8416666666666667\n",
      "it 150 acc 0.8416666666666667\n",
      "it 160 acc 0.8416666666666667\n",
      "it 170 acc 0.8416666666666667\n",
      "it 180 acc 0.8333333333333334\n",
      "it 190 acc 0.8333333333333334\n",
      "acc 0.9\n",
      "confusion matrix\n",
      "[[12  0  0]\n",
      " [ 0  6  3]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    " \n",
    " \n",
    "# Split the data into training/testing sets\n",
    "# training  80% testing 20%\n",
    "n = X.shape[0]\n",
    "n_test = int(np.rint(0.2 * n)) \n",
    " \n",
    "# random sort\n",
    "idx = np.random.permutation(n)\n",
    "X = X[idx, :] \n",
    "y = y[idx]\n",
    " \n",
    "X_train = X[:-n_test, :]\n",
    "y_train = y[:-n_test]\n",
    " \n",
    "X_test = X[-n_test:,:]\n",
    "y_test = y[-n_test:]\n",
    "\n",
    "\n",
    "\"\"\" data normalization, improve convergence \"\"\"\n",
    "#\"X_Train 150 x4 d = 4\n",
    "#\"mu es un vector de tamaño 4\n",
    "#\"dst es un vector de tamaño 4 \n",
    "mu = np.mean(X_train, axis = 0)\n",
    "dst = np.std(X_train, axis = 0)\n",
    "X_train = (X_train - mu) / dst\n",
    "X_test = (X_test - mu) / dst\n",
    "\"\"\"-------------------------------------------\"\"\"\n",
    " \n",
    "SM = softmaxreg.SoftmaxReg(3)\n",
    "coeff = SM.fit(X_train, y_train)\n",
    "\"\"\" prediction on test \"\"\"\n",
    "y_pred = SM.predict(X_test)\n",
    "acc = metrics.multiclass_accuracy(y_test, y_pred)\n",
    "print('acc {}'.format(acc))\n",
    "#  \n",
    "# # show confusion matrix\n",
    "# print(y_pred.shape)\n",
    "# print(y_test.shape)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, 3)\n",
    "\n",
    "print('confusion matrix')\n",
    "print(cm)\n",
    "#  \n",
    "# # Just data visualization\n",
    "# #  #project 2D\n",
    "# # reducer = umap.UMAP()\n",
    "# # print('UMAP', flush = True)\n",
    "# # reducer.fit(X) \n",
    "# # embedding = reducer.transform(X)\n",
    "# # print(embedding.shape)\n",
    "# # plt.scatter(embedding[:, 0], embedding[:, 1], c=y, cmap='Paired') \n",
    "# # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
